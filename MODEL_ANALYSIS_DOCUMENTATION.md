# Fake News Detection Model - Pattern Analysis Documentation

## Project: Fake News Detection Using Feature-Based Optimized Multi-class SVM with Firefly Algorithm

---

##  Table of Contents
1. [Overview](#overview)
2. [Model Pipeline](#model-pipeline)
3. [Text Preprocessing](#text-preprocessing)
4. [Feature Extraction (TF-IDF)](#feature-extraction-tf-idf)
5. [Dimensionality Reduction (PCA)](#dimensionality-reduction-pca)
6. [Feature Selection (Firefly Algorithm)](#feature-selection-firefly-algorithm)
7. [Classification (Multi-class SVM)](#classification-multi-class-svm)
8. [Pattern Analysis](#pattern-analysis)
9. [Multi-class Categories](#multi-class-categories)
10. [Sentence-Level Analysis](#sentence-level-analysis)

---

## 1. Overview

This model detects fake news by analyzing **linguistic patterns** in text. It was trained on the **PolitiFact dataset** containing fact-checked political claims with ratings from "Pants on Fire" (completely false) to "True" (verified accurate).

### Key Components:
- **TF-IDF Vectorization**: Converts text to numerical features
- **PCA**: Reduces feature dimensions from 10,000+ to 300
- **Firefly Algorithm**: Optimizes feature selection to ~160 best features
- **Multi-class SVM**: Classifies text into 5 truth categories

---

## 2. Model Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INPUT TEXT                                    â”‚
â”‚         "Scientists claim new discovery cures cancer"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 1: TEXT PREPROCESSING                        â”‚
â”‚  â€¢ Convert to lowercase                                              â”‚
â”‚  â€¢ Remove punctuation and special characters                         â”‚
â”‚  â€¢ Remove stopwords (the, is, at, which, etc.)                      â”‚
â”‚  â€¢ Apply stemming (running â†’ run)                                    â”‚
â”‚  â€¢ Apply lemmatization (better â†’ good)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 2: TF-IDF VECTORIZATION                      â”‚
â”‚  â€¢ Convert words to numerical values                                 â”‚
â”‚  â€¢ Calculate Term Frequency (TF) for each word                      â”‚
â”‚  â€¢ Calculate Inverse Document Frequency (IDF)                        â”‚
â”‚  â€¢ Result: ~10,000+ dimensional feature vector                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 3: STANDARDIZATION                           â”‚
â”‚  â€¢ StandardScaler normalizes features                                â”‚
â”‚  â€¢ Mean = 0, Standard Deviation = 1                                  â”‚
â”‚  â€¢ Ensures all features are on same scale                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 4: PCA (Dimensionality Reduction)            â”‚
â”‚  â€¢ Reduce from 10,000+ features to 300 components                    â”‚
â”‚  â€¢ Preserves most important variance in data                         â”‚
â”‚  â€¢ Removes noise and redundant features                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 5: FIREFLY OPTIMIZATION                      â”‚
â”‚  â€¢ Bio-inspired optimization algorithm                               â”‚
â”‚  â€¢ Selects ~160 most discriminative features                        â”‚
â”‚  â€¢ Fireflies move towards brighter ones (better solutions)          â”‚
â”‚  â€¢ Maximizes classification accuracy                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 6: SVM CLASSIFICATION                        â”‚
â”‚  â€¢ Support Vector Machine with C=400                                 â”‚
â”‚  â€¢ Finds optimal hyperplane to separate classes                      â”‚
â”‚  â€¢ Outputs decision score for classification                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OUTPUT                                       â”‚
â”‚  Decision Score â†’ Multi-class Category                               â”‚
â”‚  Score < -1.2  â†’ Pants on Fire (ğŸ”¥)                                 â”‚
â”‚  Score < -0.4  â†’ False (âŒ)                                          â”‚
â”‚  Score < 0.4   â†’ Half True (âš–ï¸)                                     â”‚
â”‚  Score < 1.2   â†’ Mostly True (âœ”ï¸)                                   â”‚
â”‚  Score >= 1.2  â†’ True (âœ…)                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Text Preprocessing

### What happens to your text:

```python
Original:  "BREAKING: Scientists CLAIM new discovery CURES cancer!!!"
           â†“
Lowercase: "breaking: scientists claim new discovery cures cancer!!!"
           â†“
No Punct:  "breaking scientists claim new discovery cures cancer"
           â†“
No Stops:  "breaking scientists claim discovery cures cancer"
           â†“
Stemmed:   "break scientist claim discoveri cure cancer"
```

### Stopwords Removed:
- Common words: the, is, at, which, on, a, an, and, or, but, in, of, to
- These words don't help distinguish fake from real news

### Stemming Examples:
| Original | Stemmed |
|----------|---------|
| running | run |
| scientists | scientist |
| discovered | discover |
| curing | cure |

---

## 4. Feature Extraction (TF-IDF)

### What is TF-IDF?

**TF (Term Frequency)**: How often a word appears in the text
```
TF = (Number of times word appears) / (Total words in document)
```

**IDF (Inverse Document Frequency)**: How unique/rare the word is
```
IDF = log(Total documents / Documents containing the word)
```

**TF-IDF Score** = TF Ã— IDF

### Example:
| Word | TF | IDF | TF-IDF | Meaning |
|------|-----|-----|--------|---------|
| "the" | 0.05 | 0.1 | 0.005 | Common, low importance |
| "cancer" | 0.02 | 2.5 | 0.050 | Specific, higher importance |
| "breakthrough" | 0.01 | 4.0 | 0.040 | Rare, potentially sensational |

---

## 5. Dimensionality Reduction (PCA)

### Why PCA?
- Original TF-IDF creates 10,000+ features (one per unique word)
- Too many features = slow training, overfitting
- PCA reduces to 300 principal components

### How it works:
```
10,000+ TF-IDF features â†’ PCA â†’ 300 components

These 300 components capture the PATTERNS that matter most
for distinguishing fake from real news.
```

---

## 6. Feature Selection (Firefly Algorithm)

### What is Firefly Optimization?

A **bio-inspired algorithm** that mimics how fireflies attract each other:
- Brighter fireflies attract dimmer ones
- Brightness = Classification accuracy
- Fireflies move towards better solutions

### Process:
```
300 PCA features â†’ Firefly Algorithm â†’ ~160 selected features

The algorithm tests different feature combinations and keeps
the ones that give the highest accuracy in classification.
```

### Why 160 features?
- Optimal balance between accuracy and speed
- Removes noisy/redundant features
- Focuses on most discriminative patterns

---

## 7. Classification (Multi-class SVM)

### Support Vector Machine (SVM)

SVM finds the **optimal hyperplane** that separates classes with maximum margin.

```
                    FAKE                    TRUE
                      â”‚                       â”‚
     â—  â—  â—         â”‚         â—‹  â—‹  â—‹
        â—  â—  â—      â”‚      â—‹  â—‹  â—‹  â—‹
           â—  â—  â—   â”‚   â—‹  â—‹  â—‹
              â—  â—   â”‚   â—‹  â—‹
                     â”‚
              â† margin â†’
              
â— = Fake news samples
â—‹ = True news samples
â”‚ = Decision boundary (hyperplane)
```

### Decision Score:
- **Negative scores** â†’ Towards FAKE class
- **Positive scores** â†’ Towards TRUE class
- **Magnitude** â†’ Confidence level

---

## 8. Pattern Analysis

### Patterns That Indicate FAKE News:

| Pattern Type | Examples | Why It's Suspicious |
|--------------|----------|---------------------|
| **Sensationalism** | "SHOCKING", "BREAKING", "EXPLOSIVE" | Emotional manipulation |
| **Vague Sources** | "Scientists say", "Experts claim" | Unverifiable |
| **Exaggeration** | "100% proven", "Never before seen" | Overclaiming |
| **Conspiracy Language** | "What they don't want you to know" | Fear-based |
| **Urgency** | "Share before it's deleted" | Pressure tactics |
| **All Caps** | "EXPOSED!", "SHOCKING TRUTH!" | Sensationalism |
| **Excessive Punctuation** | "!!!", "???" | Emotional appeal |

### Patterns That Indicate TRUE News:

| Pattern Type | Examples | Why It's Credible |
|--------------|----------|-------------------|
| **Named Sources** | "Dr. John Smith at Harvard" | Verifiable |
| **Specific Data** | "15.3% increase in Q2 2025" | Precise facts |
| **Neutral Language** | "reportedly", "according to" | Balanced |
| **Multiple Sources** | "Three independent studies show" | Corroboration |
| **Specific Dates** | "On January 15, 2026" | Verifiable timeline |
| **Attribution** | "The report published in Nature" | Academic/official |

### Word Patterns Learned from PolitiFact:

**High FAKE Score Words:**
```
shocking, miracle, cure, secret, exposed, conspiracy, 
they don't want, mainstream media, hoax, cover-up,
breaking, urgent, share this, you won't believe
```

**High TRUE Score Words:**
```
according to, research indicates, study found, 
percent increase, published in, data shows,
professor, university, official statement, 
reported by, statistics show
```

---

## 9. Multi-class Categories

### PolitiFact Rating Scale:

| Category | Score Range | Description |
|----------|-------------|-------------|
| ğŸ”¥ **Pants on Fire** | < -1.2 | Completely false, absurd claim |
| âŒ **False** | -1.2 to -0.4 | Statement is not accurate |
| âš–ï¸ **Half True** | -0.4 to 0.4 | Partially accurate, missing context |
| âœ”ï¸ **Mostly True** | 0.4 to 1.2 | Accurate with minor issues |
| âœ… **True** | > 1.2 | Statement is accurate |

### Decision Score Interpretation:

```
Score: -2.5  â†’  Very strong FAKE signal (Pants on Fire)
Score: -1.0  â†’  Moderate FAKE signal (False)
Score:  0.0  â†’  Uncertain (Half True)
Score:  0.8  â†’  Moderate TRUE signal (Mostly True)
Score:  2.0  â†’  Very strong TRUE signal (True)
```

---

## 10. Sentence-Level Analysis

### How It Works:

1. **Split text into sentences** using punctuation (. ! ?)
2. **Analyze each sentence separately** through the same pipeline
3. **Color-code results** based on individual scores

### Color Coding:

| Color | Score | Meaning |
|-------|-------|---------|
| ğŸ”´ Red | < -0.5 | Likely False - This sentence may contain misinformation |
| ğŸŸ¡ Yellow | -0.5 to 0.3 | Uncertain - Needs fact-checking |
| ğŸŸ¢ Green | > 0.3 | Likely True - This sentence appears accurate |

### Example Analysis:

```
Input: "Scientists discovered a miracle cure. The study was 
        published in Nature journal. Share before they delete this."

Sentence 1: "Scientists discovered a miracle cure"
  â†’ Score: -1.5 â†’ ğŸ”´ Likely False (vague source + "miracle")

Sentence 2: "The study was published in Nature journal"
  â†’ Score: 0.8 â†’ ğŸŸ¢ Likely True (specific source)

Sentence 3: "Share before they delete this"
  â†’ Score: -1.8 â†’ ğŸ”´ Likely False (urgency + conspiracy)
```

---

## ğŸ“Š Model Performance Metrics

| Metric | Score |
|--------|-------|
| Accuracy | ~92% |
| Precision | ~91% |
| Recall | ~90% |
| F1-Score | ~90% |

---

## âš ï¸ Limitations

1. **English Only** - Model trained on English text only
2. **Political Focus** - Best for political claims (PolitiFact dataset)
3. **Training Era** - Trained on 2016-2018 data
4. **Pattern-Based** - Analyzes language patterns, not actual facts
5. **Context Needed** - Short sentences may give less reliable results

---

## ğŸ”§ Technical Details

### Model Files:
| File | Description |
|------|-------------|
| `model/tfidf.pckl` | TF-IDF Vectorizer |
| `model/scaler.pckl` | Standard Scaler |
| `model/pca.pckl` | PCA Model |
| `model/firefly.npy` | Selected Feature Indices |
| `model/svm.pckl` | Trained SVM Classifier |

### Training Dataset:
- **Source**: PolitiFact fact-check database
- **Size**: ~12,000+ claims
- **Labels**: Multi-class (6 original categories)

---

## ğŸ“š References

1. PolitiFact - www.politifact.com
2. Firefly Algorithm - Yang, X.S. (2008)
3. Support Vector Machines - Cortes & Vapnik (1995)
4. TF-IDF - Salton & Buckley (1988)

---

*Document generated for Fake News Detection System*
*Using Feature-Based Optimized Multi-class SVM with Firefly Algorithm*
